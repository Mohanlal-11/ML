{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c51aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "bn_eps = 0.0001\n",
    "bn_momentum = 0.03\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=None, acti=\"leaky\"):\n",
    "        super().__init__()\n",
    "        if padding is None:\n",
    "            padding = kernel_size // 2\n",
    "            \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=bn_eps, momentum=bn_momentum)\n",
    "        if acti == \"relu\":\n",
    "            self.acti = nn.ReLU(inplace=True)\n",
    "        elif acti == \"leaky\":\n",
    "            self.acti = nn.LeakyReLU(0.1015625, inplace=True)\n",
    "        # elif acti == \"mish\":\n",
    "        #     self.acti = Mish()\n",
    "            \n",
    "        self.fused = False\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if not self.training and self.fused:\n",
    "            return self.acti(self.fused_conv[0](x))\n",
    "        else :\n",
    "            return self.acti(self.bn(self.conv(x)))\n",
    "\n",
    "class Focus(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv = Conv(4 * in_channels, out_channels, kernel_size)\n",
    "        # self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(f'in foucus : {x.shape}')\n",
    "        concat = torch.cat((x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]), 1)\n",
    "        return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e8f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitSpatial(nn.Module):\n",
    "    def __init__(self,in_ch):\n",
    "        super(SplitSpatial, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, in_ch, kernel_size=2, stride=2, bias=False).requires_grad_(False)  \n",
    "        self.conv2 = nn.Conv2d(in_ch, in_ch, kernel_size=2, stride=2, bias=False).requires_grad_(False)  \n",
    "        self.conv3 = nn.Conv2d(in_ch, in_ch, kernel_size=2, stride=2, bias=False).requires_grad_(False)  \n",
    "        self.conv4 = nn.Conv2d(in_ch, in_ch, kernel_size=2, stride=2, bias=False).requires_grad_(False)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            wts1 = torch.zeros(in_ch, in_ch, 2,2)\n",
    "            wts2 = torch.zeros(in_ch, in_ch, 2,2)\n",
    "            wts3 = torch.zeros(in_ch, in_ch, 2,2)\n",
    "            wts4 = torch.zeros(in_ch, in_ch, 2,2)\n",
    "            for i in range(in_ch):\n",
    "                wts1[i, i, 0, 0] = 1\n",
    "                wts2[i, i, 1, 0] = 1\n",
    "                wts3[i, i, 0, 1] = 1\n",
    "                wts4[i, i, 1, 1] = 1\n",
    "\n",
    "            self.conv1.weight.copy_(wts1)\n",
    "            self.conv2.weight.copy_(wts2)\n",
    "            self.conv3.weight.copy_(wts3)\n",
    "            self.conv4.weight.copy_(wts4)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x4 = self.conv4(x)\n",
    "        return torch.cat((x1, x2, x3, x4), dim=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d2f13a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 12, 160, 160]), torch.Size([1, 12, 160, 160]), True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "tens = torch.rand(1,3,320,320)\n",
    "default = Focus()\n",
    "own = SplitSpatial(in_ch=3)\n",
    "\n",
    "def_out = default(tens)\n",
    "own_out = own(tens)\n",
    "def_out.shape, own_out.shape, torch.equal(def_out, own_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2acc51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mohanlal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
